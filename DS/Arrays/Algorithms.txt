â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ğŸ“Œ ARRAY OPERATIONS â€” COMPLETE MASTER GUIDE      â”‚
â”‚                     Step-by-Step Algorithm Blueprints               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¯ UNDERSTANDING THE NOTATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â€¢ arr[] - The array we're working with
â€¢ n - Size of the array (arr.size() or sizeof(arr)/sizeof(arr[0]))
â€¢ i, j, k - Index variables for loops
â€¢ val - Value to insert/search/delete
â€¢ pos - Position/index in array (0-based)
â€¢ temp - Temporary variable for swapping

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1ï¸âƒ£ ARRAY ACCESS â€” "Direct Memory Addressing"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ EXACT STEP-BY-STEP ALGORITHM:

Step 1: ğŸ¯ Understand that array access is O(1) operation
        Memory address = base_address + (index * element_size)

Step 2: ğŸ” Valid index check (CRITICAL STEP):
        if (index < 0 OR index >= n):
            Throw IndexOutOfBoundsException
            OR return error value

Step 3: ğŸ“Š Direct memory calculation:
        element_address = arr + (index * sizeof(element_type))

Step 4: ğŸ”„ Read operation:
        value = arr[index]
        OR value = *(arr + index)  // Pointer arithmetic

Step 5: âœï¸ Write operation:
        arr[index] = new_value
        OR *(arr + index) = new_value

Step 6: âš ï¸ Boundary considerations:
        - C++ arrays: No bounds checking (dangerous!)
        - std::vector: vec.at(index) throws exception
        - std::array: arr.at(index) throws exception

ğŸ”„ VISUALIZATION OF MEMORY ACCESS:
Array: [10, 20, 30, 40, 50]
Base address: 0x1000, int size: 4 bytes

Access arr[2]:
Address = 0x1000 + (2 * 4) = 0x1008
Value at 0x1008 = 30 âœ“

Access arr[5]: âŒ ERROR!
Index 5 >= size 5 â†’ Out of bounds

âš¡ KEY POINTS:
â€¢ Random access - any element in constant time
â€¢ Memory is contiguous - enables pointer arithmetic
â€¢ Index validation is programmer's responsibility in C-style arrays
â€¢ Modern C++ containers provide safer access methods

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
2ï¸âƒ£ ARRAY TRAVERSAL â€” "Visiting Every Element"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ EXACT STEP-BY-STEP ALGORITHMS:

â”â”â”â”â” A. FORWARD TRAVERSAL (LEFT TO RIGHT) â”â”â”â”â”
Step 1: ğŸ¯ Initialize loop counter: i = 0

Step 2: ğŸ”„ Loop condition: while i < n

Step 3: ğŸ“Š Access current element: arr[i]

Step 4: ğŸ¯ Process element (print, modify, analyze)

Step 5: ğŸ”„ Increment: i = i + 1

Step 6: âœ… Continue until i == n

Code Pattern:
for(int i = 0; i < n; i++) {
    // Process arr[i]
}

â”â”â”â”â” B. BACKWARD TRAVERSAL (RIGHT TO LEFT) â”â”â”â”â”
Step 1: ğŸ¯ Start from end: i = n - 1

Step 2: ğŸ”„ Loop while: i >= 0

Step 3: ğŸ“Š Access: arr[i]

Step 4: ğŸ¯ Process element

Step 5: ğŸ”„ Decrement: i = i - 1

Code Pattern:
for(int i = n-1; i >= 0; i--) {
    // Process arr[i]
}

â”â”â”â”â” C. RANGE-BASED TRAVERSAL (C++11) â”â”â”â”â”
Step 1: ğŸ¯ Let compiler handle indices

Step 2: ğŸ”„ For each element in array

Step 3: ğŸ“Š Access element directly

Code Pattern:
for(auto& element : arr) {
    // Process element
}

â”â”â”â”â” D. TWO-POINTER TRAVERSAL â”â”â”â”â”
Step 1: ğŸ¯ Initialize: left = 0, right = n-1

Step 2: ğŸ”„ While left <= right

Step 3: ğŸ“Š Process arr[left] and arr[right]

Step 4: ğŸ”„ Update: left++, right--

Code Pattern:
int left = 0, right = n-1;
while(left <= right) {
    // Process arr[left] and arr[right]
    left++; right--;
}

ğŸ”„ VISUALIZATION:
Array: [10, 20, 30, 40, 50]

Forward: 10 â†’ 20 â†’ 30 â†’ 40 â†’ 50
Backward: 50 â†’ 40 â†’ 30 â†’ 20 â†’ 10
Two-pointer: (10,50) â†’ (20,40) â†’ (30)

âš¡ KEY POINTS:
â€¢ Forward traversal is most common
â€¢ Backward useful for reverse operations
â€¢ Range-based is clean but loses index information
â€¢ Two-pointer efficient for symmetric operations

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
3ï¸âƒ£ ARRAY INSERTION â€” "Making Room for New Elements"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ EXACT STEP-BY-STEP ALGORITHMS:

â”â”â”â”â” A. INSERT AT END (EASIEST) â”â”â”â”â”
Step 1: âœ… Check capacity: if size < capacity

Step 2: ğŸ¯ Direct assignment: arr[size] = new_value

Step 3: ğŸ”„ Update size: size = size + 1

Step 4: âœ… Return success

Complexity: O(1) - just assign and increment

â”â”â”â”â” B. INSERT AT BEGINNING (MOST COSTLY) â”â”â”â”â”
Step 1: âœ… Check capacity: if size < capacity

Step 2: ğŸ¯ Shift all elements right (start from end):
        for i = size-1 down to 0:
            arr[i+1] = arr[i]

Step 3: ğŸ“Š Insert at position 0: arr[0] = new_value

Step 4: ğŸ”„ Update size: size++

Complexity: O(n) - must shift n elements

â”â”â”â”â” C. INSERT AT SPECIFIC POSITION â”â”â”â”â”
Step 1: âœ… Validate position: 0 <= pos <= size

Step 2: âœ… Check capacity: size < capacity

Step 3: ğŸ¯ Shift elements from pos to end right:
        for i = size-1 down to pos:
            arr[i+1] = arr[i]

Step 4: ğŸ“Š Insert at position: arr[pos] = new_value

Step 5: ğŸ”„ Update size: size++

Complexity: O(n) - shifting required

â”â”â”â”â” D. INSERT IN SORTED ARRAY (MAINTAIN ORDER) â”â”â”â”â”
Step 1: âœ… Find correct position (binary search):
        pos = find_insertion_position(arr, new_value)

Step 2: ğŸ¯ Shift elements from pos onward right

Step 3: ğŸ“Š Insert at pos: arr[pos] = new_value

Step 4: ğŸ”„ Update size

ğŸ”„ VISUALIZATION:
Array: [10, 20, 30, 40, _, _] (size=4, capacity=6)

Insert 50 at end: [10,20,30,40,50,_] âœ“

Insert 5 at beginning:
Step 1: Shift: [10,20,30,40,50,50] (i=4)
        [10,20,30,40,40,50] (i=3)
        [10,20,30,30,40,50] (i=2)
        [10,20,20,30,40,50] (i=1)
        [10,10,20,30,40,50] (i=0)
Step 2: Insert: [5,10,20,30,40,50] âœ“

Insert 25 at position 2:
Shift from index 2: [10,20,30,40,50,50] â†’ [10,20,30,30,40,50] â†’ [10,20,25,30,40,50] âœ“

âš¡ KEY POINTS:
â€¢ Insertion cost depends on position
â€¢ End insertion is cheap (O(1))
â€¢ Beginning/middle insertion is expensive (O(n))
â€¢ Always check capacity before insertion
â€¢ Consider dynamic arrays (vectors) for flexible sizing

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
4ï¸âƒ£ ARRAY DELETION â€” "Removing and Compacting"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ EXACT STEP-BY-STEP ALGORITHMS:

â”â”â”â”â” A. DELETE FROM END (EASIEST) â”â”â”â”â”
Step 1: âœ… Check if array not empty: size > 0

Step 2: ğŸ¯ Simply reduce size: size = size - 1

Step 3: âš ï¸ Optional: Clear value arr[size] = 0/default

Step 4: âœ… Return deleted value (if needed)

Complexity: O(1) - just decrement size

â”â”â”â”â” B. DELETE FROM BEGINNING (MOST COSTLY) â”â”â”â”â”
Step 1: âœ… Check if array not empty

Step 2: ğŸ¯ Store value to return: deleted = arr[0]

Step 3: ğŸ”„ Shift all elements left:
        for i = 1 to size-1:
            arr[i-1] = arr[i]

Step 4: ğŸ”„ Update size: size--

Step 5: âš ï¸ Optional: Clear last element arr[size] = 0

Step 6: âœ… Return deleted value

Complexity: O(n) - must shift n-1 elements

â”â”â”â”â” C. DELETE FROM SPECIFIC POSITION â”â”â”â”â”
Step 1: âœ… Validate position: 0 <= pos < size

Step 2: ğŸ¯ Store value: deleted = arr[pos]

Step 3: ğŸ”„ Shift elements from pos+1 to end left:
        for i = pos+1 to size-1:
            arr[i-1] = arr[i]

Step 4: ğŸ”„ Update size: size--

Step 5: âš ï¸ Optional: Clear last element

Step 6: âœ… Return deleted value

Complexity: O(n) - shifting required

â”â”â”â”â” D. DELETE BY VALUE (SEARCH AND DELETE) â”â”â”â”â”
Step 1: ğŸ” Find position of value: pos = search(arr, value)

Step 2: âœ… If found (pos != -1): Delete from position pos

Step 3: âœ… If not found: Return "not found" error

Step 4: âš ï¸ If multiple occurrences: Delete all or first?

ğŸ”„ VISUALIZATION:
Array: [10, 20, 30, 40, 50] (size=5)

Delete from end: [10,20,30,40,_] (size=4)

Delete from beginning:
Step 1: Store deleted = 10
Step 2: Shift: [20,30,40,50,50] â†’ [20,30,40,50,_] (size=4)
Result: [20,30,40,50]

Delete element at position 2 (value=40):
Shift: [20,30,50,50,_] â†’ [20,30,50,_,_] (size=3)

âš¡ KEY POINTS:
â€¢ Deletion cost depends on position
â€¢ End deletion is cheap (O(1))
â€¢ Beginning/middle deletion is expensive (O(n))
â€¢ Physical deletion vs logical deletion (marking)
â€¢ Consider trade-off: shift now vs mark for later cleanup

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
5ï¸âƒ£ ARRAY SEARCHING â€” "Finding Needles in Haystacks"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ EXACT STEP-BY-STEP ALGORITHMS:

â”â”â”â”â” A. LINEAR SEARCH (SEQUENTIAL) â”â”â”â”â”
Step 1: ğŸ¯ Start from beginning: i = 0

Step 2: ğŸ”„ While i < n:

Step 3: ğŸ” Compare: if arr[i] == target:

Step 4: âœ… Found: return i (position)

Step 5: ğŸ”„ Else: i = i + 1

Step 6: âœ… End of array: return -1 (not found)

Complexity: O(n) worst case, O(1) best case (first element)

â”â”â”â”â” B. BINARY SEARCH (ONLY SORTED ARRAYS) â”â”â”â”â”
Step 1: âœ… Precondition: Array must be sorted

Step 2: ğŸ¯ Initialize: left = 0, right = n-1

Step 3: ğŸ”„ While left <= right:

Step 4: ğŸ“Š Calculate mid: mid = left + (right - left) / 2

Step 5: ğŸ” Compare:
        if arr[mid] == target: return mid
        if arr[mid] < target: left = mid + 1
        if arr[mid] > target: right = mid - 1

Step 6: âœ… Not found: return -1

Complexity: O(log n) - halves search space each time

â”â”â”â”â” C. SENTINEL LINEAR SEARCH (OPTIMIZED) â”â”â”â”â”
Step 1: ğŸ¯ Store last element: last = arr[n-1]

Step 2: ğŸ“Š Replace last with target: arr[n-1] = target

Step 3: ğŸ”„ i = 0
        while arr[i] != target:
            i = i + 1

Step 4: âœ… Restore last element: arr[n-1] = last

Step 5: ğŸ“Š Check result:
        if i < n-1 OR last == target: return i
        else: return -1

Complexity: O(n) but fewer comparisons per iteration

â”â”â”â”â” D. INTERPOLATION SEARCH (UNIFORMLY DISTRIBUTED) â”â”â”â”â”
Step 1: âœ… Array must be sorted and uniformly distributed

Step 2: ğŸ¯ left = 0, right = n-1

Step 3: ğŸ”„ While left <= right AND target between arr[left] and arr[right]:

Step 4: ğŸ“Š Estimate position:
        pos = left + ((target - arr[left]) * (right - left)) / (arr[right] - arr[left])

Step 5: ğŸ” Compare:
        if arr[pos] == target: return pos
        if arr[pos] < target: left = pos + 1
        else: right = pos - 1

Step 6: âœ… Not found: return -1

Complexity: O(log log n) average, O(n) worst case

ğŸ”„ VISUALIZATION:
Array: [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]

Linear search for 70:
10âŒ â†’ 20âŒ â†’ 30âŒ â†’ 40âŒ â†’ 50âŒ â†’ 60âŒ â†’ 70âœ… (position 6)

Binary search for 70:
Step 1: left=0, right=9, mid=4 â†’ arr[4]=50 < 70
Step 2: left=5, right=9, mid=7 â†’ arr[7]=80 > 70  
Step 3: left=5, right=6, mid=5 â†’ arr[5]=60 < 70
Step 4: left=6, right=6, mid=6 â†’ arr[6]=70 âœ…

âš¡ KEY POINTS:
â€¢ Choose algorithm based on array state (sorted/unsorted)
â€¢ Linear search: Simple, works on any array
â€¢ Binary search: Fast but requires sorted array
â€¢ Consider preprocessing cost if frequent searches
â€¢ Sentinel search reduces comparison overhead

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
6ï¸âƒ£ ARRAY SORTING â€” "Organizing Chaos"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ KEY SORTING ALGORITHMS (Summarized):

â”â”â”â”â” BUBBLE SORT â”â”â”â”â”
For i = 0 to n-2:
    For j = 0 to n-i-2:
        If arr[j] > arr[j+1]:
            Swap arr[j] and arr[j+1]

â”â”â”â”â” SELECTION SORT â”â”â”â”â”
For i = 0 to n-2:
    min_idx = i
    For j = i+1 to n-1:
        If arr[j] < arr[min_idx]:
            min_idx = j
    Swap arr[i] and arr[min_idx]

â”â”â”â”â” INSERTION SORT â”â”â”â”â”
For i = 1 to n-1:
    key = arr[i]
    j = i-1
    While j >= 0 AND arr[j] > key:
        arr[j+1] = arr[j]
        j--
    arr[j+1] = key

â”â”â”â”â” QUICK SORT (PARTITION) â”â”â”â”â”
Function partition(arr, low, high):
    pivot = arr[high]
    i = low - 1
    For j = low to high-1:
        If arr[j] <= pivot:
            i++
            Swap arr[i] and arr[j]
    Swap arr[i+1] and arr[high]
    Return i+1

â”â”â”â”â” MERGE SORT (MERGE) â”â”â”â”â”
Function merge(left, right):
    result = []
    i = j = 0
    While i < left.size AND j < right.size:
        If left[i] <= right[j]:
            result.append(left[i])
            i++
        Else:
            result.append(right[j])
            j++
    Append remaining elements

âš¡ SORTING SELECTION GUIDE:
â€¢ Small arrays (n<50): Insertion sort
â€¢ General purpose: Quick sort or std::sort
â€¢ Need stability: Merge sort
â€¢ Memory constrained: Heap sort
â€¢ Integers with small range: Counting sort
â€¢ Large integers: Radix sort

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
7ï¸âƒ£ DYNAMIC ARRAYS (VECTORS) â€” "Flexible Containers"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ EXACT STEP-BY-STEP OPERATIONS:

â”â”â”â”â” A. CREATION AND INITIALIZATION â”â”â”â”â”
Step 1: ğŸ¯ Include header: #include <vector>

Step 2: ğŸ“Š Declaration: vector<type> vec;

Step 3: ğŸ”„ Optional initialization:
        â€¢ vector<int> vec1;               // Empty
        â€¢ vector<int> vec2(5);            // 5 elements, value-initialized
        â€¢ vector<int> vec3(5, 100);       // 5 elements, all 100
        â€¢ vector<int> vec4 = {1,2,3,4,5}; // Initializer list

â”â”â”â”â” B. AUTOMATIC RESIZING (AMORTIZED O(1)) â”â”â”â”â”
When capacity exceeded:
Step 1: ğŸ¯ Allocate new larger array (typically 2x size)

Step 2: ğŸ”„ Copy all elements to new array

Step 3: ğŸ“Š Update internal pointers

Step 4: âš ï¸ Delete old array

Step 5: âœ… Continue operation

â”â”â”â”â” C. COMMON OPERATIONS â”â”â”â”â”
â€¢ Add element: vec.push_back(value)     // O(1) amortized
â€¢ Remove last: vec.pop_back()           // O(1)
â€¢ Insert at position: vec.insert(pos, value)  // O(n)
â€¢ Delete at position: vec.erase(pos)          // O(n)
â€¢ Access: vec[index] or vec.at(index)         // O(1)
â€¢ Size: vec.size()                            // O(1)
â€¢ Capacity: vec.capacity()                    // O(1)

â”â”â”â”â” D. MEMORY MANAGEMENT â”â”â”â”â”
â€¢ Reserve: vec.reserve(n)  // Pre-allocate memory
â€¢ Shrink: vec.shrink_to_fit()  // Reduce capacity to size
â€¢ Clear: vec.clear()  // Remove all elements
â€¢ Swap: vec1.swap(vec2)  // Exchange contents

ğŸ”„ VISUALIZATION OF VECTOR GROWTH:
Initial: vec = [], capacity = 0
push_back(1): vec = [1], capacity = 1
push_back(2): Need more space!
              Allocate new[2], copy [1]
              vec = [1,2], capacity = 2
push_back(3): Need more space!
              Allocate new[4], copy [1,2]
              vec = [1,2,3], capacity = 4
push_back(4): vec = [1,2,3,4], capacity = 4
push_back(5): Need more space!
              Allocate new[8], copy [1,2,3,4]
              vec = [1,2,3,4,5], capacity = 8

âš¡ KEY POINTS:
â€¢ Amortized O(1) push_back due to exponential growth
â€¢ Use reserve() if you know approximate size
â€¢ Prefer vector over C-arrays for safety
â€¢ Iterators remain valid until reallocation

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
8ï¸âƒ£ MULTIDIMENSIONAL ARRAYS â€” "Tables and Matrices"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ EXACT STEP-BY-STEP ALGORITHMS:

â”â”â”â”â” A. 2D ARRAY DECLARATION â”â”â”â”â”
Fixed size (stack):
int arr[3][4];  // 3 rows, 4 columns

Dynamic size (heap):
int** arr = new int*[rows];
for(int i=0; i<rows; i++)
    arr[i] = new int[cols];

Using vector:
vector<vector<int>> arr(rows, vector<int>(cols));

â”â”â”â”â” B. TRAVERSAL PATTERNS â”â”â”â”â”
Row-major (default in C/C++):
for(int i=0; i<rows; i++)
    for(int j=0; j<cols; j++)
        process(arr[i][j]);

Column-major:
for(int j=0; j<cols; j++)
    for(int i=0; i<rows; i++)
        process(arr[i][j]);

Diagonal traversal:
// Main diagonal
for(int i=0; i<min(rows,cols); i++)
    process(arr[i][i]);

// Anti-diagonal  
for(int i=0; i<min(rows,cols); i++)
    process(arr[i][cols-1-i]);

â”â”â”â”â” C. COMMON OPERATIONS â”â”â”â”â”
Matrix addition:
for(i=0 to rows-1)
    for(j=0 to cols-1)
        C[i][j] = A[i][j] + B[i][j]

Matrix multiplication:
for(i=0 to rowsA-1)
    for(j=0 to colsB-1) {
        sum = 0
        for(k=0 to colsA-1)
            sum += A[i][k] * B[k][j]
        C[i][j] = sum
    }

Transpose:
for(i=0 to rows-1)
    for(j=i+1 to cols-1)
        swap(arr[i][j], arr[j][i])

â”â”â”â”â” D. MEMORY LAYOUT â”â”â”â”â”
Row-major: [R1C1, R1C2, R1C3, R2C1, R2C2, R2C3]
Address: base + (i * cols + j) * sizeof(element)

Column-major: [R1C1, R2C1, R3C1, R1C2, R2C2, R3C2]
Address: base + (j * rows + i) * sizeof(element)

ğŸ”„ VISUALIZATION:
3x3 Matrix:
[1, 2, 3]
[4, 5, 6]
[7, 8, 9]

Memory (row-major): [1,2,3,4,5,6,7,8,9]
Access [1][2] (second row, third column):
Address = base + (1*3 + 2)*4 = base + 20 bytes

âš¡ KEY POINTS:
â€¢ C/C++ uses row-major order
â€¢ Cache performance better with sequential access
â€¢ Jagged arrays possible with vectors
â€¢ Consider flattened 1D array for performance

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
9ï¸âƒ£ COMMON MISTAKES AND PITFALLS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âŒ MISTAKE 1: Off-by-one errors
Problem: for(i=0; i<=n; i++)  // Should be i<n
Solution: Always test loop boundaries
         Use half-open ranges: [0, n)

âŒ MISTAKE 2: Buffer overflow
Problem: arr[10] but access arr[10]
Solution: Validate indices before access
         Use .at() method for bounds checking

âŒ MISTAKE 3: Memory leaks (dynamic arrays)
Problem: int* arr = new int[n]; ... // No delete[]
Solution: Use RAII: vector<int> arr(n);
         Or smart pointers

âŒ MISTAKE 4: Assuming arrays are passed by value
Problem: void func(int arr[5]) // Actually passes pointer
Solution: Pass size explicitly: void func(int arr[], int n)
         Or use std::array/vector

âŒ MISTAKE 5: Incorrect size calculation
Problem: sizeof(arr) / sizeof(arr[0]) on pointer
Solution: Only works on stack arrays
         For functions, pass size as parameter

âŒ MISTAKE 6: Uninitialized arrays
Problem: int arr[5]; // Contains garbage
Solution: int arr[5] = {}; // Zero-initialized
         Or explicitly initialize all elements

âŒ MISTAKE 7: Modifying array while iterating
Problem: for(i=0; i<n; i++) { if(cond) delete arr[i]; }
Solution: Collect indices to delete, then delete in reverse
         Or use iterator invalidation-aware methods

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”Ÿ COMPLEXITY ANALYSIS SUMMARY
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

OPERATION                  | STATIC ARRAY   | DYNAMIC ARRAY (VECTOR)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Access by index           | O(1)           | O(1)
Search (unsorted)         | O(n)           | O(n)
Search (sorted)           | O(log n)       | O(log n)
Insert at end             | O(1)*          | O(1) amortized
Insert at beginning       | O(n)           | O(n)
Insert at middle          | O(n)           | O(n)
Delete from end           | O(1)           | O(1)
Delete from beginning     | O(n)           | O(n)
Delete from middle        | O(n)           | O(n)
Sort                      | O(n log n)     | O(n log n)
Traversal                 | O(n)           | O(n)

*Only if space available, otherwise impossible

MEMORY COMPLEXITY:
â€¢ Static array: Fixed at compile time
â€¢ Dynamic array: O(n) current size, O(capacity) allocated

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¯ PRACTICAL IMPLEMENTATION TIPS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. âœ… ALWAYS validate array bounds before access
2. âœ… PREFER std::vector over C-style arrays for safety
3. âœ… USE reserve() when you know approximate size to avoid reallocations
4. âœ… CHOOSE appropriate traversal pattern for cache efficiency
5. âœ… CONSIDER algorithm complexity before implementation
6. âœ… TEST edge cases: empty array, single element, full array
7. âœ… DOCUMENT assumptions about array state (sorted/unsorted)
8. âœ… USE standard library algorithms when available
9. âœ… PROFILE before optimizing - measure actual performance
10. âœ… UNDERSTAND memory layout for multidimensional arrays

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’ GOLDEN RULES FOR ARRAY PROGRAMMING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. **KNOW YOUR DATA STRUCTURE**: Arrays are not lists. Random access is fast, insertions/deletions are slow.

2. **CHOOSE WISELY**: Static arrays for fixed-size data, vectors for dynamic data, multidimensional arrays for tabular data.

3. **MEMORY MATTERS**: Contiguous memory gives cache benefits but limits flexibility.

4. **ALGORITHMS OVER IMPLEMENTATION**: Often, the right algorithm matters more than micro-optimizations.

5. **SAFETY FIRST**: Bounds checking may cost performance but prevents catastrophic errors.

6. **STL IS YOUR FRIEND**: Standard Template Library provides optimized, tested implementations.

7. **MEASURE, DON'T GUESS**: Profile your code to find actual bottlenecks.

8. **LEARN THE TRADE-OFFS**: Every operation has time/space complexity implications.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸš€ FINAL THOUGHT:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Arrays are the most fundamental data structure - simple, efficient, 
and powerful in their constraints. Mastering array operations is not 
just about learning syntax; it's about understanding memory, algorithms, 
and trade-offs. From direct memory access to complex sorting algorithms, 
arrays teach us the essential principles that underpin all advanced 
data structures. Remember: the simplest tools, when wielded with skill 
and understanding, can solve the most complex problems.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â¡ï¸ NEXT STEPS: Implement each operation, test with various inputs,
              analyze performance, and build intuition through practice!
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”